{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d98e978-4549-47f4-984f-85f183706479",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Relevance Inference\n",
    "This notebook takes in the extracted text from PDF preprocessing stage, the fine tuned relevance model from the training stage, and performs inference on the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c027591e-edf8-4b5b-8b29-1f74d20527da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02/2021 21:32:28 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.models.relevance_infer import TextRelevanceInfer\n",
    "from config_farm_train import InferConfig\n",
    "import config\n",
    "from src.data.s3_communication import S3Communication\n",
    "from dotenv import load_dotenv\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5532cf65-84d9-4790-bfa9-f58e89f7b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd13d4d-925d-4be0-93f2-b1463cdd5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"S3_ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"S3_SECRET_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d26d30-1ec1-4343-a551-d0b27f825909",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config = InferConfig(\"infer_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf9efe0-8728-4a86-aeea-d0c1168b1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Automation using Elyra and Kubeflow Pipelines,\n",
    "# set AUTOMATION = 1 as an environment variable\n",
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # extracted pdfs\n",
    "    if not os.path.exists(config.BASE_EXTRACTION_FOLDER):\n",
    "        config.BASE_EXTRACTION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    # inference results dir\n",
    "    if not os.path.exists(infer_config.result_dir['Text']):\n",
    "        pathlib.Path(infer_config.result_dir['Text']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # load dir\n",
    "    if not os.path.exists(infer_config.load_dir['Text']):\n",
    "        pathlib.Path(infer_config.load_dir['Text']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download extracted pdfs from s3 \n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_EXTRACTION_S3_PREFIX,\n",
    "    config.BASE_EXTRACTION_FOLDER,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fa59b1-4fc0-4e03-8d0b-9066d0643bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = pathlib.Path(infer_config.load_dir['Text']).parent\n",
    "model_rel_zip = pathlib.Path(model_root, 'RELEVANCE.zip')\n",
    "s3c.download_file_from_s3(model_rel_zip, config.CHECKPOINT_S3_PREFIX, \"RELEVANCE.zip\")\n",
    "with zipfile.ZipFile(pathlib.Path(model_root, 'RELEVANCE.zip'), 'r') as z:\n",
    "    z.extractall(model_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf22ac3-2a27-40ce-a59f-e1b7c96089af",
   "metadata": {},
   "source": [
    "However, we advise that you manually update the parameters in the corresponding config file\n",
    "\n",
    "`esg_data_pipeline/config/config_farm_trainer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da3ba2-6a6c-459f-be90-cd6ede593f47",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8dfe2-5b84-4b2a-ae90-03d14a2807a9",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750dcc9b-fd03-4f7e-91cc-f7350897ba43",
   "metadata": {},
   "source": [
    "The following cell will load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394e543f-507b-4450-9493-f9e734186972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': '/opt/app-root/src/extend-demo2/aicoe-osc-demo/models/RELEVANCE'}\n",
      "/opt/app-root/src/extend-demo2/aicoe-osc-demo/data/extraction\n",
      "{'Text': '/opt/app-root/src/extend-demo2/aicoe-osc-demo/data/infer'}\n"
     ]
    }
   ],
   "source": [
    "print(infer_config.load_dir)\n",
    "print(infer_config.extracted_dir)\n",
    "print(infer_config.result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992f3875-85dc-4bf2-ac01-59c107142de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02/2021 21:33:10 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "11/02/2021 21:33:11 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "11/02/2021 21:33:11 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n"
     ]
    }
   ],
   "source": [
    "component = TextRelevanceInfer(infer_config) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51bdd61-ed72-491b-bf92-d3006761f3ba",
   "metadata": {},
   "source": [
    "### Prediction on a Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0522d7ba-538b-4503-8f11-2decbcb78244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'text_classification',\n",
       "  'task_name': 'text_classification',\n",
       "  'predictions': [{'start': None,\n",
       "    'end': None,\n",
       "    'context': 'Is the company going to go green?|The company is going to reduce 8% in gas production',\n",
       "    'label': '0',\n",
       "    'probability': 0.82192034}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"The company is going to reduce 8% in gas production\"\n",
    "input_question = \"Is the company going to go green?\"\n",
    "component.run_text(input_text=input_text, input_question=input_question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c465be-fd3b-4e31-9561-8d9a14fe22bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'text_classification',\n",
       "  'task_name': 'text_classification',\n",
       "  'predictions': [{'start': None,\n",
       "    'end': None,\n",
       "    'context': 'Is the company going to go green?|The company is about semi conductors',\n",
       "    'label': '0',\n",
       "    'probability': 0.82192034}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"The company is about semi conductors\"\n",
    "input_question = \"Is the company going to go green?\"\n",
    "component.run_text(input_text=input_text, input_question=input_question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60bba1-2a06-4067-baf0-04dd4220bc38",
   "metadata": {},
   "source": [
    "### Prediction on an Entire Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a1b23-011c-40e9-b04a-a8ce9fd896fb",
   "metadata": {},
   "source": [
    "`run_folder()` will make prediction on all the JSON files in the /data/extraction folder. This will take some time, based on the number of json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d2c9f-be3a-4856-a956-d6d0f5694574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02/2021 21:33:12 - INFO - src.models.relevance_infer -   #################### Starting Relevence Inference for the following extracted pdf files found in /opt/app-root/src/extend-demo2/aicoe-osc-demo/data/infer:\n",
      "['75506106_BOA_2016-12-31', '88094292_Carriage Svcs Inc_2019-07-23', '90044053_Fisher & Paykel Hl_2017-11-07'] \n",
      "11/02/2021 21:33:12 - INFO - src.models.relevance_infer -   #################### 1/3 PDFs\n",
      "11/02/2021 21:33:12 - INFO - src.models.relevance_infer -   Running inference for 75506106_BOA_2016-12-31:\n",
      "11/02/2021 21:33:12 - INFO - src.models.relevance_infer -   ###### Received 606 examples for Text, number of questions: 24\n"
     ]
    }
   ],
   "source": [
    "component.run_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78421f-ace9-4c19-ab0f-65e31fabcd06",
   "metadata": {},
   "source": [
    "The results are saved in a CSV. For each table, the extracted text, as well as the page number from the source pdf file are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef54093-09ae-4fb9-bb77-6d71693a01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getenv(\"AUTOMATION\"):\n",
    "    df_table_results = pd.read_csv(infer_config.result_dir['Text'] + \"/sustainability-report-2019_predictions_relevant.csv\")\n",
    "    df_table_results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c992b-5460-4af8-ae15-09e68b4d62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the predicted files to s3\n",
    "s3c.upload_files_in_dir_to_prefix(\n",
    "    infer_config.result_dir['Text'],\n",
    "    config.BASE_INFER_S3_PREFIX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226fc3d-87dc-432a-a571-5109d0ecfc86",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook ran the _Relevance_ inference on a sample dataset and stored the output in a csv format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
